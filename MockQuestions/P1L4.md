1. What are the image points that are considered correspondences in Computer Vision tasks?
2. Why is it difficult to establish correspondences between image points in different views of a scene?
3. How can two images of the same scene be aligned to create a larger image in panorama stitching?
4. What is the minimum number of correspondences required to estimate a homography for aligning images in panorama stitching?
5. What are salient points in the context of panorama stitching, and why are they important?
6. How are local descriptions computed for salient points in panorama stitching?
7. What is the purpose of comparing descriptions in panorama stitching?
8. What are the properties of good detectors in the context of local invariant features?
9. Why is repeatability an important property for detectors in local invariant feature detection?
10. What does it mean for a descriptor to have distinctiveness versus robustness trade-off?
11. Why is compactness an important property for descriptors in local invariant feature detection?
12. What is the role of speed in detector and descriptor computation in local invariant feature detection?
13. How does the Moravec Interest Point Detector determine the cornerness of a pixel?
14. How does the Harris Corner Detector improve upon the Moravec Interest Point Detector?
15. What is the Harris equation used in the Harris Corner Detector?
16. How does the Harris Corner Detector compute the structure matrix?
17. How does rotation invariance affect the eigenvalues computed in the Harris Corner Detector?
18. Why is the Harris cornerness function not invariant to illumination changes?
19. Why is the Harris Corner Detector not scale invariant?
20. What is the role of image smoothing in achieving scale invariance in local invariant feature detection?
21. What is scale space, and how does it address the scale invariance problem?
22. What is the Gaussian Scale-Space, and how is it created?
23. How is feature detection and scale selection performed in the Gaussian Scale-Space?
24. What is the scale-normalized Laplacian of Gaussian (LOG), and how does it help in scale selection?
25. How does the Difference of Gaussian (DoG) function approximate the scale-normalized LOG?
26. What are the key differences between the DoG and LOG detectors?
27. How is the DoG computed in an octave of the scale space?
28. How is non-maxima suppression performed in the DoG detector considering the scale dimension?
29. What is the purpose of padding in the DoG detector, and how does it enable detection at multiple scale levels?
30. How is the size of the kernel controlled in the DoG detector to handle large scales?