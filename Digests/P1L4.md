# Local invariant feature
Several times in CV you can find tasks that deal with find corresponding points. 
This is difficult because the same point can look different in different views. 

### Panorama stitching
Your phone can do that.
It creates a large image by estimating a homography, which requires at least 4 corresponding points.

### The local invariant features paradigm
The task of finding correspondences is split into 3 steps:
1. __Detection__ of _salient points_
2. __Description__: computation of a suitable descriptor based on the pixel in the neighbourhood of the points
3. __Matching__ between decriptors

_Descriptors_ should be _invariant_ (robust) to as many transformations as possible. 

### Good Detector properties
- __Repeatability__: it should find the _same keypoints_ in different views/transformations of the scene
- __Saliency__: it must found keypoints that are surrounded by _salient patterns_ (i.e. good for discrimination).

### Good Descriptor properties
- __Distinctiveness vs. Robustness Trade-off__: the description algorithm should capture the salient information around a keypoint. 
- Compactness: the descriptor should be as compact/coincise as possible. 

Speed is extremely important for detectors, since they have to be run on the whole image. 

#### Moravec Interest point detector
The cornerness at $p$ is given by the _minimum squared difference_ between the _patch_ (e.g. 7x7) centered at $p$ and those centered at its 8 _neighbours_.
![[moravec_intereset_point_detector.png]]

## Harris corner detector
It uses Mavec's interest point detector, and assume that we shift the image with a generic shift $(\Delta x, \Delta y)$:
- $w(x,y)$ is a __window__ _set to 1_ around the _pixel_ under evaluation and 0 _in all the image_ 
- in the end consider only the pixel around the $x,y$ position 
![[harris1.png]]
![[harris2.png]]
$M$ is the __structure matrix__, and encodes the _local image structure_. 
Now, let's hypotesize $M$ as a _diagonal matrix_. 
- $\lambda_1, \lambda_2 \sim 0$, then it's flat
- $\lambda_1 >> \lambda_2$, there's an edge
- $\lambda_1, \lambda_2 \uparrow$, then it's a corner

Since $M$ is real and symmetric, it can be _diagonalized_, and be rotated into the matrix that we wanted. 
- The columns of $R$ are the __orthogonal unit eigenvectors__ of $M$ 
- $λ_i$ the corresponding _eigenvalues_. 
- $R^T$ is the _rotation matrix_ that _aligns_ the _image axes_ to the _eigenvectors_ of $M$
![[M_is_real.png]]

Since we would need to compute _eigenvalues_ at each pixel would be _costly_, 
we compute a more efficient “_cornerness_” function: 
![[corenerness_function.png]]
![[C_values.png]]

#### To summarize:
Harris corner detection works this way:
1. Compute $C$ _at each pixel_
2. Select all pixels where $C$ _is higher_ than a _threshold_ $T$
3. Within the previous set of points, select only the points which are the local maxima of $C$ (through NMS)

$w(x,y)$ is a Gaussian, to give more weight to nearby pixels and less to the others. 

## Invariance properties
Our model is rotation invariant, since the _eigenvalues_ of $M$ are invariant to the rotation of the matrix.

#### Illumination invariance
It's not always subject to illumanation invariance:
- It is light invariant for an _addictive factor_, since the computation of the gradient causes the additive factor to be deleted.
- But, that's not true for _multiplicative factors_, since derivatives get multiplied by the same factor. 

### Scale invariance
There's no scale invariance!
In fact, if we keep the same window size, edges might be recognized as corners when scaling. 

Since we need features in order to match descriptors, we mostly need _large scale features_, which are richer of details. 
- So, we cancel out all finer-details which do not appear across the range of scales and that should be cancelled-out through __image smoothing__. 

## Scale-space
A _Scale-Space_ is a one-parameter _family of images_ created _from the original_ one so that the structures at smaller scales are successively _suppressed_ by _smoothing operations_.
- the more you smooth, the more small details increasingly disappear. 

The scale space must be realized through __Gaussian Smoothing__
$$
L(x, y, \sigma) = G(x,y,\sigma) * I(x,y)
$$
A Scale-Space is created by repeatedly _smoothing_ the _original image_ with _larger and larger __Gaussian__ kernels_.

## Multi-scale feature detection
How do we establish a scale in which features become interesting?

This problem consists on __multi-scale feature detection__ and __automatic scale selection__.
To find an answer to this, we must compute combinations of _scale normalized derivatives_ of the Gaussian Scale-space and find their _extrema_.

- As we filter more (_higher sigma_), derivatives tends to become _weaker_.

#### Scale-normalized laplacian of gaussian
Scale-normalized Laplacian of Gaussian (LOG):
![[laplacian_of_gaussian.png]]

The idea is to look for _extrema_ across $x, y, σ$ 
- meaning, that we have found a feature that has a _position_ given by $x$ and $y$ and a _scale_ given by the _sigma_ at which it is _maximum_.

Features (_Blob-like_) and scales detected as _extrema_ of the scale-normalized LOG.

## Difference of Gaussian (DoG)
Lowe proposes to detect keypoints by seeking for the extrema of the _DoG_ (_Difference of Gaussian_) function across the $(x,y,σ)$ domain:
![[doggy.png]]

Lowe proves that this is a scaled version of Lindberg. $(k-1)$ is a _constant factor_, it does _not influence extrema location_ => the choice of $k$ is _not critical_.
Both detectors are rotation invariant and find blob-like features (circularly symmetric filters).

-----
[...]

### Matching SIFTs
When matching descriptors, use the NN algorithm to find matching descriptors  from a $T$ image ($q$) with descriptors from a reference image $p_i$. 
- __Euclidian distance__ is used.

### Validanting Matches 
So, the found NN does not mean that is valid, since some feature present in $T$ may just not have a correspondant feature in $R$.
We have to use a threshold. 
![[thres_NN.png]]

### Efficient NN-Search
Efficient _indexing_ techniques are exploited to _speed-up_ the NN-search process.
- The main indexing technique exploited for feature matching is known as __k-d tree__, _Best Bin First_ (BBF). 
- Unlike the basic k-d tree, the _BBF_ is efficient also in _high-dimensional spaces_ such as _descriptor spaces_.