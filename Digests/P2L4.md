[..]

## CNNs
[..]

#### Equivariance 
So, convolutions (aka correlations) are _equivariant_ wrt _translation_, but not wrt to rotation or scale. 

#### Multiple input channel
While we have 3 dimensions in convolution, this is still a 2D operation: the kernel is slid on only 2 dimension, and computes all 3 layers at the same time. 

#### Activation
As we slide the kernel onto the image, we obtain a _single value output_, called __activation__. It's also called __feature map__.

#### Convolutional layer composed of many filters
We can add multiple kernels/filters to a single layer, in order to obtain a _set of filters_.
The final equation that we'll obtain for the conv layer is this:
![[overall.png]]
Remember this like the ave maria:
- _The number of __output channels__ is equal to the __number of kernels___. 

## Introducing non-linearity
Since CNNs as of now are basically contrained linear operator, to meaningfully connect them we need some kind of non-linear operators. 

#### Padding (valid padding)
If we have no padding in the input (aka __valid padding__) we may shrink our feature maps, according to this formulas:
$ğ»_{ğ‘œğ‘¢ğ‘¡} = ğ»_{ğ‘–ğ‘›} âˆ’ ğ»_{ğ‘˜} + 1$
$ğ‘Š_{ğ‘œğ‘¢ğ‘¡} = ğ‘Š_{ğ‘–ğ‘›} âˆ’ ğ‘Š_{ğ‘˜} + 1$

#### Zero padding
A common solution is to add 0s to the initial image, in this way we preserve the dimension following this equation:
$ğ»_{ğ‘œğ‘¢ğ‘¡} = ğ»_{ğ‘–ğ‘›} âˆ’ ğ»_{ğ‘˜} + 1 + 2P$
$ğ‘Š_{ğ‘œğ‘¢ğ‘¡} = ğ‘Š_{ğ‘–ğ‘›} âˆ’ ğ‘Š_{ğ‘˜} + 1 + 2P$

### Receptive fields
The _input pixels_ affecting a _hidden unit_ are called its __receptive field__.
If we apply a $H_k \times W_k$ kernel at each layer, the receptive field size of an element in the $L$-th activation would be:
$$r_L = [L(H_k-1)+1]\times[L(W_k-1)+1]$$
Where $L$ is the number of layers. 
Since the receptive field size grows linearly with the number of layers, to capture large features we may need a huge number of layers. 
- Instead, we __downsample__ the activations inside the network. 

##### Strided convolutions
If we apply a $ğ»_ğ¾$ Ã— $ğ‘Š_ğ¾$ kernel size at each layer, but with stride $ğ‘†_ğ‘™$ at layer ğ‘™, the receptive field of an element in the ğ¿-th activation has size:
![[strided_form.png]]
i.e., the _size of the receptive field_ grows __exponentially__ with respect to the _number of layers_ with stride > 1.

The output size with these two formulas is defined as:
$$
\begin{matrix}
ğ»_{ğ‘œğ‘¢ğ‘¡} = \lfloor\dfrac{ğ»_{ğ‘–ğ‘›}âˆ’ğ»_{ğ¾}+2ğ‘ƒ}{S}\rfloor + 1 \\
ğ‘Š_{ğ‘œğ‘¢ğ‘¡} = \lfloor\dfrac{ğ‘Š_{ğ‘–ğ‘›}âˆ’ğ‘Š_{ğ¾}+2ğ‘ƒ} {S}\rfloor+ 1
\end{matrix}
$$
## Layers in CNNs
Some other layers in CNNs are:
- _non-linear activation functions_ 
- _fully connected layers_ 
- __pooling__ layers 
- __(batch-)normalization layers__

### Pooling layers
Pooling layers are layers that aggregate several values into a single output value through a function, using a _prespecified (not learned) kernel_.

Key differences with normal convolutions:
- each input channel is _computed independently_.
- consequently, $C_{out}$ = $C_{in}$.

Using pooling layers is an apriori decision, since I can't learn this type of kernels (especially max-pooling).

#### Max-pooling
![[max_pooling.png]]
__Downsampling comes from stride__, _not from pooling_!!!
Compared to strided convolutions, max pooling 
- has _no learnable parameters_ (pro and con). 
- provides _invariance_ to small _spatial shifts_.

## Flattening tensors
To be inputted inside a _Dense layer_, the image is flattened. 
In CNNs
- the convolutionals part is called __feature extractor__.
- the dense part is called __classifier__.

The Dense part of the CNN has a global vision of the image.

----
