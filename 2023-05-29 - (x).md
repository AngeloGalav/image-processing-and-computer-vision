[..]

At training time, the batch normalization layer has the most "variance"...
[...]
In order to wipe the activation at test time, you use this final value.

At test time, the mean and variance are just constant-> we will have a more deterministic behaviour at test time. 

We can fuse 2 linear layer with just one.
![[bn.png]]
Since it is more stable, you can also have higher learning rates. 

Pros 
- allows the use of higher learning rates 
- careful initialization is less important 
- Training is not deterministic, acts as regularization 
- No overhead at test-time: can be fused with previous layer 
Cons 
- Not clear why it is so beneficial 
- Need to distinguish between training and testing time makes implementations more complex, source of many bugs 
- Does not scale down to “micro-batches”

In this case also, 

## Batch Norm for convolutional layers
Batch norm for convolutional layers Normalize along mini-batch and spatial dimensions -> out activation has 4 dimensions:
![[batch_norm_cnn.png]]
In the end, I will have a ... for each output channel. 

## Batch Norm alternatives
[he will not ask this stuff]
There are alternatives to Batch Norm:
![[batch_norm_alternatives.png]]

-----
# Successful Architectures
## AlexNet
![[cnn2.png]]
- The convolutions are the smallest cube in this image
- We need 48+(other, different)48 kernels, since we have [...] 
	- half of them run on the top GPU, the other half on the bottom GPU. Each GPU only sees the channels of the kernel that its processing (__group convolutions__, used to split load across GPUs). 
	- There's communication[??? see lesson again]

#### Architecture breakdown

- First layer is a 96x11x11 _convolutional layer_, with __stride 4__. We will see again this _stem layer_ at the beginning of convnets, i.e. a conv layer that performs a fast reduction in the spatial size of the activations, mainly to reduce memory and computational cost, but also to rapidly _increase the receptive field_ (it increases in size very quickly).

Example [here](https://virtuale.unibo.it/pluginfile.php/1640876/mod_resource/content/1/IPCV_P2L5_architectures.pdf). 