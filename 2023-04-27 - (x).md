---
TODO:
- persi i primi 20 minuti
- inserire immagini
- da riguardare alcune parti
---

[...]

Persi i primi 10 minuti

## Perspective projection matrix
![[perspective_projection_matrix.png]]

## Canonical perspective projection
ğ‘· is a 3x4 matrix with full rank. The most basic PPM is
$$
P â‰¡ [ğ‘° |0]
$$
This form is useful to understand the core operations carried out by perspective projection, i.e. scaling lateral coordinates ($ğ‘¥, ğ‘¦$) according to the distance from the camera ($ğ‘§$). The above form is usually referred to as canonical or standard PPM.

A general PPM can then be factorized as $ğ‘· â‰¡ ğ‘¨ [ğ‘° | ğŸ] ğ‘®$, i.e. it can be thought of as carrying out _three fundamental operations in sequence_:
1. Convert coordinates from WRF to CRF 
2. Perform canonical perspective projection, i.e. divide by the third coordinate 
3. Apply camera specific transformations: i.e. where is my reference frame etc...

From it, we get another useful factorization of a generic PPM as 
[image here]

## Lens distortion
The PPM is based on the pinhole camera model.
However, real lenses introduce distortions wrt to the pure pinhole model (in particular, for cheap and/or short focal length lenses).
We often need to model also the effects caused by the optical distortion induced by lenses 
- Lens distortion is modelled through additional parameters that do not alter the form of the PPM

[image here]

We do not need to change the camera model, we stay with the pinhole camera model. Infact, we never once changed the model from the pinhole camera model. 
\[ \useless
Even if we introduce thin lenses, these lenses are not so thin [..]

Perspective projections preserves colinearity (it preserves lines), though it does not preserve parallelism (the angles change). In reality, different position of the lenses will bend light differently.
useless\ \]
For the purpose of having a good model, we need to take into account the real lenses distortions -> _we need new parameters_ to take this into account!

### Modeling lens distortion

- The most significant deviation from the ideal pinhole model is known as __radial distortion__ (lens â€œcurvatureâ€). It depends on the image radius -> is more evident the further you are. 
- Second order effects are induced by __tangential distortion__ (â€œmisalignmentsâ€ of optical components and/or defects). 

Lens distortion is modelled through a non-linear transformation which maps ideal (i.e., undistorted) image coordinates into the observed (i.e., distorted) image coordinates.

[image here]

$(x, y)$ is the actual output of the image, while $x_{undistorted}$ refers to the undistorted, real image that we would have with a ideal model.
The output is influenced by the __distance__ $r$ from the __distortion centre__, which is usually assumed to correspond with the piercing point $c = [0,0]^T$, $r = \sqrt{(x_{undist})^2 + (y_{undist})^2)}$.


### Types of lens distortions
- Barrel distortion is a lens defect that causes straight lines to bend outwards and is most noticeable along the edges â—¦ It is associated with wide-angle lenses 
- Pincushion distortion is the opposite of barrel distortion, it causes straight lines to curve inward from the edges to the middle â—¦ Telephoto lenses are most commonly associated with pincushion distortion


### Modelling lens distortion 2
The _radial distortion function_ $L(r)$ is defined for positive r only and such that L(0) = 1. This non-linear function is typically approximated by its _Taylor series_ (up to a certain approximation order)
$$
L(r) = 1 + k_1r^2 + k_2r^4  + k_3r^6
$$
The _tangential distortion vector_ is instead approximated as follows:
[image here]

The parameters $p_1$ and $p_2$ weight the amount of distortion that we have in the model. 

The _radial distortion coefficients_ $ğ‘˜_1 , ğ‘˜_2 , â€¦ , ğ‘˜_n$ together with the _two tangential distortion coefficients_ $ğ‘_1$ and $ğ‘_2$ form the set of the lens distortion parameters, which extends the set of __intrinsic parameters__ required to build _a realistic camera model_.

### Lens distortion within the image formation process
Lens distortion is modelled as a non-linear mapping _taking place after canonical perspective projection_ onto the image plane. Afterwards, the intrinsic parameter matrix allow applying an affine transformation which maps continuous image coordinates into pixel coordinates.
Accordingly, the image formation flow with lenses can be summarized as follows:
[list here]


## Complete camera model
![[complete_camera_model.png]]
![[camera_calib_2.png]]
Given (a lot of) pairs $(ğ‘š^{(ğ‘–)} , ğ‘€_ğ‘Š^{(ğ‘–)} )$, estimate the parameters $M_c$ for a specific camera and setup.

# Calibration
We have now defined a camera model thoroughly explaining the image formation and digitization process. Such a model is the _PPM_ $ğ‘·$ (+ _distortion coefficients_), which in turn can be decomposed into 3 independent elements: 
- __intrinsic parameter matrix__ (ğ‘¨) 
- __rotation matrix__ (ğ‘¹) 
- __translation vector__ (ğ’•) 

_Camera calibration_ is the process whereby all parameters defining the camera model are (as accurately as possible) estimated for a specific camera device. 
Depending on the application, either the PMM only or also its independent components $(A, R, t)$ need to be estimated.

## Calibration patterns
Camera calibration approaches can be split into two main categories: 
- Those relying on a single image of a 3D calibration object 
	- featuring several (at least 2) planes containing a known pattern 
- Those relying on several (at least 3) different images of one given planar pattern.

In practice, it is difficult to build accurate targets containing multiple planes, while an accurate planar target can be attained rather easily Implementing a camera calibration software requires a significant effort 
- the main Computer Vision toolboxes include specific functions (OpenCV, Matlab CC Toolbox)

## Zhang's method
![[zhang_method.png]]

### Calibration pattern
Given a chessboard pattern, we know: 
- The _number of internal corners_ of the pattern, usually odd along one dimension and even along the other to remove rotation ambiguities. 
- The _size of the squares_ that form the pattern (in mm, cm...)
Internal corners can be detected easily by standard algorithms (e.g. the Harris corner detector)

### 3D coordinates
The World Reference Frame can be conveniently defined. In an unambiguous pattern, the WRF:
- has its origin always in the same corner (e.g., the one next to the dark square on the right of the chessboard if both dark squares are on top) 
- has plane ğ‘§ = 0 given by the pattern itself => the third coordinate is always 0 
- and the $ğ‘¥, ğ‘¦$ axes are aligned to the chessboard (e.g., ğ‘¥ along the short side and ğ‘¦ along the long one).
Given such rules and the known square side, it is possible to define 3D coordinates for all corners in an image of the pattern.
![[image_chessboard.png]]

## Extrinsic parameters
The World Reference Frame is different for each calibration image. _The $[ğ‘¹ \ ğ’•]$ are estimated wrt the World Reference System attached to the target_, which _moves with the pattern_. Therefore, we estimate as many extrinsic matrices as the number of images used for calibration (usually 10 to 20 images of the pattern).
![[checkboard_1.png]]

The WRF remains the same in any direction of the pattern, it doesnt change if I move the camera. 

Can it be the same PPM for the two images?
- NO! SInce we have a different relationship between the input, the same 3D point and \[...\].

What changes in these PPMs is the relative position of the camera. 
- Some thigns _remains unchanged_: $A$, $k_1... k_n$, $p_1$ and $p_2$ remain the same. 

## Zhang step 2 -> For each image compute an initial guess homography $ğ»_ğ‘–$

### ğ‘ƒ as a Homography
Due to the choice of the WRF associated with calibration images, in each of them we consider only 3D points with $ğ‘§ = 0$. 
Accordingly, the PPM for points on the pattern can be simplified to a 3x3 matrix:
![[P_as_homography.png]]
\[? what is matrix P??\]
This is true only from points on the plane/pattern. 

\[to _rewrite_\]
Since \[..\], now the  PPM is a 3x3 matrix, not
The homogenous coordinates of a 2D point in 
the projective planes are the sensor and the pattern. 
And it's a semplification of the PPM 

H can be seen as a relation between these two planes
\[end to rewrite\]

Such a transformation, denoted here as $ğ‘¯$, is known as homography and represents a general transformation between projective planes.
$ğ‘¯$ can be thought of as a simplification of $ğ‘·$ in case the imaged object is planar.

## Estimating $ğ»_ğ‘–$ (DLT algorithm)
Given the image of a pattern with $ğ‘š$ corners, we can write 3 linear equations for each corner $ğ‘—$ where: 
- 3D coordinates are known due to the WRF definition 
- 2D coordinates are known due to corners having been detected in the $i$-th image â—¦
- the unknowns are the 9 elements in $ğ»_i$
![[equations.png]]

Stacking $3ğ‘š$ such equations for the $ğ‘š$ corners we get a system of equations, butâ€¦ How do we solve a system of equations in a projective space?

When are two 3D points equivalent in $â„™^2$?
![[two_points_equivalent.png]]
Two points lay on the same line if their cross product is the zero vector.
![[estimating_algorithm.png]]

Given $ğ‘š$ corners, we can create a _homogeneous_, _overdetermined linear system of equations_:
![[bho.png]]

In standard linear algebra, there's no solution to that (we can only compute solution if the matrix is squared). 

To avoid the trivial solution ğ’‰ = ğŸ we look for solutions with an additional constraint, e.g., $||ğ’‰|| = 1$.

#### Singular Value Decomposition
The solution $ğ’‰^âˆ—$ is found by minimizing the norm of the vector $ğ‘³h$:
![[svd.png]]
It is known from linear algebra that the solution to such problem can be found via __Singular Value Decomposition__ of $ğ¿$. In particular, the solution is $ğ’‰^âˆ— = ğ’—_ğŸ—$, i.e., the last column of $V$:
![[svd_2.png]]
Finding the solution in this equation is not meant in a linear algebra sense, but rather in a LSQ problem sense. 