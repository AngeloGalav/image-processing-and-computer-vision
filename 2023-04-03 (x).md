---
TODO:
- bisogna vedere la lezione prima per capire...
- nell'ultima parte mi si è spento il pc...
---

## Difference of Gaussian
We use the difference of Gaussian to find the features. 
Blobs are extremas, so they do not change with scales.

[..]

For 5 level of smoothing, we compute several gaussian smoothed function within an octave. For each pair, we take the differences, we then seek for extremas in the DOGs. 
![[dogs_octave.png]]

Level of difference with Gaussian.
In order to compute maxima extrema on the DOG, I have to consider the neighbourhood, but to define the neighbourhood here, I have to \[...\]
![[dogs_octave_2.png]]

I can compute the maximum for the bottom layer or the upper layer. Just by computing these 5 layers ... Which is a bit limiting -> I simply add a couple of layer to my space, as seen in the picture. 
- Now instead of just 3 levels of extrema, I can compute 4 levels of extrema. 
- Features can now appear in images at 4 scale levels. 

Can we create even more smoothing levels?
The dimension of the kernel depending on $\sigma$, $k = \lceil 3\sigma\rceil$ -> smoothing with a large level of sigma is not right, since a bigger sigma implies a bigger kernel, and thus more computation. 

To increase the number of levels, rather than doubling $\sigma$, we _shrink_ the image (halving the number of both rows and columns) and just keep the same set of kernels. 

![[dog_tuning.png]]

Extrema detection: a point (x,y,σ) is detected as a keypoint iff its DoG is higher (lower) than that of the 26 neighbours (8 at the same scale and 18=9+9 at the two nearby scales) in the (x,y,σ) space • According to the original article (parameter tuning) • the best number of scales within an octave is s=3 • initial σ for each octave should be • the input image is enlarged by a factor of 2 in both dimensions.

5 level of filterning for s = 3. 

This is the best situation for us. 

## Exemplar DoG keypoints
- Extrema featuring weak DoG response turn out scarcely repeatable…prune weak responses.
- Lowe also notices that unstable keypoints featuring a sufficiently strong DoG may be found along edges and devises a further pruning step
![[dog_keypoints_example.png]]
We can solve the problem of points in the sky by using a threshold to DoG values. 
But there's another thing we can do:

The size of the circle is proportional to the scale of the feature (σ), in particular, it's proportional to the sigma which is found to be an extrema (the detector provides you with this information).

The circular gaussian simmetry are rotation, scale invariant. 

darker area and a lighter area. 
\[..\]

We need to identify a prominent direction inherent to the patch (i.e. the canonical orientation) and, based on such direction, define a local reference frame. A reasonable choice consists in identifying the direction along which most of the gradient is found.

When computing the descriptor, pixel coordinates are taken in the local reference frame.

## Scale and Rotation Invariance Description
- We need to define a Scale and Rotation Invariant Description 
- Most keypoint detection algorithms follow an approach close to Lowe’s one 
	- i.e. finding extrema across a stack of images computed while increasing a scale parameter 

- Once each keypoint has been extracted, a surrounding patch is considered to compute its descriptor (scale and rotation invariant) 
	- Scale invariance: the patch is taken from the stack of images ($L(x, y, \sigma)$ in Lowe’s) that correspond to the characteristic scale 
	- Rotation invariance: a canonical (aka characteristic) patch orientation is computed, so that the descriptor can then be computed on a canonically-oriented patch 
		- Orientation wrt a new reference system, not the one of the image

### Canonical Orientation
Lowe proposes to compute the canonical orientation of DoG keypoints as follows: • Given the keypoint, the magnitude and orientation of the gradient are computed at each pixel of the associated Gaussian-smoothed image, $L$:
![[canonical_orientation.png]]

You use the magnitude to weight how much 
\[..\]

## SIFT Descriptor
I'm going to orient according to the canonical orientation. 

[..]
Adding 
[..]

- The first level of normalization provides us with a strong intensity change. 

Recomputing the L_2, you get a bit of robustness to non-linear complexity change. 

## Matching Process
For the matching process, we only compare the descriptors, without using the key points (which we instead used to compute the descriptors altogether). 

We use NN, and we just use a linear distance between neighbours. 
